# üìä Modelado Predictivo de Valor de Vida del Cliente (CLV)
| Autor            | Fecha        | D√≠a |
|------------------|--------------|----------|
| **Carlos V√°squez** |06 Enero 2026 | 4| 

## üéØ Objetivo del Proyecto

Construir un modelo de regresi√≥n lineal para predecir el **Customer Lifetime Value (CLV)** bas√°ndose en caracter√≠sticas del cliente como ingresos, frecuencia de compras, antig√ºedad y satisfacci√≥n.

---

## üìã Tabla de Contenidos

1. [Requisitos Previos](#requisitos-previos)
2. [Instalaci√≥n](#instalaci√≥n)
3. [Estructura del Proyecto](#estructura-del-proyecto)
4. [Ejecuci√≥n Paso a Paso](#ejecuci√≥n-paso-a-paso)
5. [Interpretaci√≥n de Resultados](#interpretaci√≥n-de-resultados)
6. [Diagn√≥stico del Modelo](#diagn√≥stico-del-modelo)
7. [Preguntas Frecuentes](#preguntas-frecuentes)

---

## üîß Requisitos Previos

### Software Necesario
- Python 3.8 o superior
- Jupyter Notebook o JupyterLab
- pip (gestor de paquetes de Python)

### Conocimientos Recomendados
- Conceptos b√°sicos de Python
- Fundamentos de estad√≠stica descriptiva
- Nociones de regresi√≥n lineal

---

## üì¶ Instalaci√≥n

### Paso 1: Crear un entorno virtual (recomendado)

```bash
# En Windows
python -m venv venv
venv\Scripts\activate

# En macOS/Linux
python3 -m venv venv
source venv/bin/activate
```

### Paso 2: Instalar dependencias

```bash
pip install pandas numpy statsmodels scikit-learn matplotlib scipy
```

### Paso 3: Instalar Jupyter Notebook

```bash
pip install jupyter
```

### Paso 4: Verificar instalaci√≥n

```python
import pandas as pd
import statsmodels.api as sm
import sklearn
print("‚úÖ Todas las bibliotecas instaladas correctamente")
```

---

## üìÅ Estructura del Proyecto

```
proyecto-clv/
‚îÇ
‚îú‚îÄ‚îÄ clv_analysis.ipynb          # Notebook principal
‚îú‚îÄ‚îÄ README.md                    # Este archivo
‚îú‚îÄ‚îÄ requirements.txt             # Dependencias del proyecto
‚îî‚îÄ‚îÄ visualizacionCompleta.png                      
```

---
## Scripts
[C√≥digo](clv_analysis.ipynb)

## Visualizacion Completa
![Gr√°ficos](visualizacionCompleta.png)

## üöÄ Ejecuci√≥n Paso a Paso

### **PASO 1: Generaci√≥n de Datos**

El c√≥digo genera autom√°ticamente un dataset sint√©tico de 200 clientes con las siguientes variables:

- **edad**: Edad del cliente (18-70 a√±os)
- **ingresos**: Ingresos anuales (distribuci√≥n log-normal)
- **frecuencia_compras**: N√∫mero de compras al a√±o
- **antiguedad_meses**: Meses como cliente
- **satisfaccion**: Nivel de satisfacci√≥n (1-10)
- **canal_adquisicion**: Online, Tienda o App
- **clv**: Variable objetivo (calculada con ruido homoced√°stico)

**¬øQu√© observar?**
- CLV promedio y rango de valores
- Correlaciones entre variables y CLV

---

### **PASO 2: Construcci√≥n de Modelos**

#### **Modelo 1: Regresi√≥n Simple**
```
CLV = Œ≤‚ÇÄ + Œ≤‚ÇÅ(ingresos) + Œµ
```

**Objetivo**: Establecer una l√≠nea base usando solo ingresos como predictor.

**M√©tricas clave**:
- **R¬≤**: Proporci√≥n de variabilidad explicada
- **RMSE**: Error promedio de predicci√≥n en d√≥lares

---

#### **Modelo 2: Regresi√≥n M√∫ltiple**
```
CLV = Œ≤‚ÇÄ + Œ≤‚ÇÅ(ingresos) + Œ≤‚ÇÇ(frecuencia_compras) + Œ≤‚ÇÉ(antiguedad_meses) + Œ≤‚ÇÑ(satisfaccion) + Œµ
```

**Objetivo**: Mejorar las predicciones incorporando m√∫ltiples factores.

**Comparaci√≥n**: El modelo m√∫ltiple deber√≠a mostrar mejoras significativas en R¬≤ y RMSE.

---

### **PASO 3: Interpretaci√≥n de Coeficientes**

Para cada variable, el c√≥digo muestra:

1. **Coeficiente (Œ≤)**: Cambio en CLV por unidad de cambio en X
2. **Intervalo de confianza (95%)**: Rango probable del efecto real
3. **Valor p**: Significancia estad√≠stica (p < 0.05 = significativo)
4. **Interpretaci√≥n pr√°ctica**: Traducci√≥n a impacto monetario

#### Ejemplo de interpretaci√≥n:

Si el coeficiente de `frecuencia_compras` es **50.23**:
- "Por cada compra adicional al a√±o, el CLV aumenta en $50.23"
- Si p < 0.05, este efecto es estad√≠sticamente significativo

---

### **PASO 4: Validaci√≥n de Supuestos**

La regresi√≥n lineal asume 4 supuestos fundamentales:

#### ‚úÖ **1. Linealidad**
- Se verifica visualmente en el gr√°fico "Residuos vs Valores Ajustados"
- **Qu√© buscar**: Puntos distribuidos aleatoriamente sin patr√≥n

#### ‚úÖ **2. Normalidad de Residuos**
- **Test de Shapiro-Wilk**: p > 0.05 indica normalidad
- **Q-Q Plot**: Puntos deben seguir la l√≠nea roja

#### ‚úÖ **3. Homocedasticidad (Varianza constante)**
- **Test de Breusch-Pagan**: p > 0.05 indica varianza constante
- **Gr√°fico de residuos**: Dispersi√≥n uniforme en todos los niveles

#### ‚úÖ **4. Independencia de Residuos**
- **Estad√≠stico Durbin-Watson**: Ideal entre 1.5 y 2.5
- Valores cercanos a 2.0 indican independencia

#### ‚úÖ **5. No Multicolinealidad**
- **VIF (Variance Inflation Factor)**: < 5 es aceptable, < 10 es tolerable
- VIF alto indica que las variables predictoras est√°n correlacionadas entre s√≠

---

### **PASO 5: Visualizaci√≥n y Diagn√≥stico**

El c√≥digo genera 4 gr√°ficos clave:

1. **Observados vs Predichos**: Eval√∫a precisi√≥n general del modelo
2. **Residuos vs Ajustados**: Detecta heterocedasticidad y no linealidad
3. **Q-Q Plot**: Verifica normalidad de residuos
4. **Importancia de Variables**: Muestra el impacto relativo de cada predictor

---

## üìä Interpretaci√≥n de Resultados

### M√©tricas del Modelo

| M√©trica | Descripci√≥n | Valor Ideal |
|---------|-------------|-------------|
| **R¬≤** | % de variabilidad explicada | > 0.70 (bueno), > 0.85 (excelente) |
| **RMSE** | Error promedio de predicci√≥n | Lo m√°s bajo posible en $ |
| **AIC** | Calidad del modelo (penaliza complejidad) | Menor es mejor |

### Interpretaci√≥n del R¬≤

- **R¬≤ = 0.95**: El modelo explica el 95% de la variabilidad en CLV
- **R¬≤ ajustado**: Considera el n√∫mero de predictores (mejor para comparar modelos)

---

## üîç Diagn√≥stico del Modelo

### ‚ö†Ô∏è Problemas Comunes y Soluciones

#### **Problema 1: Heterocedasticidad**
**S√≠ntoma**: Test Breusch-Pagan con p < 0.05

**Impacto**: 
- Los errores est√°ndar son incorrectos
- Los intervalos de confianza no son confiables
- Las pruebas de hip√≥tesis pueden ser enga√±osas

**Soluciones**:
1. Transformar la variable dependiente (log, ra√≠z cuadrada)
2. Usar errores est√°ndar robustos (HC3, HC4)
3. Modelar la varianza expl√≠citamente (WLS - Weighted Least Squares)

---

#### **Problema 2: No Normalidad de Residuos**
**S√≠ntoma**: Test Shapiro-Wilk con p < 0.05

**Impacto**:
- Los intervalos de confianza pueden ser imprecisos
- Las pruebas t pueden no ser v√°lidas (especialmente en muestras peque√±as)

**Soluciones**:
1. Transformar variables (Box-Cox)
2. Usar bootstrap para intervalos de confianza
3. Con n > 30, el Teorema Central del L√≠mite ayuda (menos cr√≠tico)

---

#### **Problema 3: Multicolinealidad Alta**
**S√≠ntoma**: VIF > 10 en alguna variable

**Impacto**:
- Coeficientes inestables
- Intervalos de confianza muy amplios
- Dif√≠cil interpretaci√≥n de efectos individuales

**Soluciones**:
1. Eliminar variables redundantes
2. Combinar variables correlacionadas
3. Usar PCA (an√°lisis de componentes principales)
4. Regularizaci√≥n (Ridge, Lasso)

---

#### **Problema 4: Autocorrelaci√≥n**
**S√≠ntoma**: Durbin-Watson < 1.5 o > 2.5

**Impacto**:
- Errores est√°ndar sesgados
- Pruebas de hip√≥tesis inv√°lidas

**Soluciones**:
1. Incluir variables temporales relevantes
2. Usar modelos de series temporales (ARIMA)
3. Errores est√°ndar HAC (Heteroskedasticity and Autocorrelation Consistent)

---

## üéì Preguntas de Verificaci√≥n

### **Pregunta 1: Interpretaci√≥n del Coeficiente de Ingresos**

**Respuesta esperada**:
Si el coeficiente es, por ejemplo, 0.02:
- "Por cada d√≥lar adicional en ingresos anuales, el CLV aumenta en $0.02"
- "Por cada $1,000 adicionales en ingresos, el CLV aumenta en $20"
- Este efecto asume que todas las dem√°s variables permanecen constantes (ceteris paribus)

**Consideraciones**:
- El intervalo de confianza del 95% proporciona el rango probable del efecto real
- El valor p indica si este efecto es estad√≠sticamente significativo
- La significancia pr√°ctica (tama√±o del efecto) es tan importante como la estad√≠stica

---

### **Pregunta 2: Supuestos Violados y su Impacto**

**An√°lisis por supuesto**:

1. **Si se viola Linealidad**:
   - Las predicciones ser√°n sistem√°ticamente sesgadas
   - El modelo subestima o sobreestima en diferentes rangos
   - **Soluci√≥n**: Agregar t√©rminos cuadr√°ticos o usar modelos no lineales

2. **Si se viola Homocedasticidad**:
   - Los intervalos de confianza son incorrectos
   - Las pruebas t pueden dar falsos positivos/negativos
   - **Soluci√≥n**: Usar errores robustos o transformar variables

3. **Si se viola Normalidad**:
   - Los intervalos de confianza pueden ser imprecisos
   - Menos cr√≠tico con muestras grandes (n > 30)
   - **Soluci√≥n**: Transformaciones o m√©todos no param√©tricos

4. **Si hay Multicolinealidad**:
   - Los coeficientes son inestables (var√≠an mucho entre muestras)
   - Las predicciones siguen siendo buenas, pero la interpretaci√≥n es dif√≠cil
   - **Soluci√≥n**: Eliminar variables redundantes o usar regularizaci√≥n

**Impacto en Confiabilidad**:
- **Predicciones**: Menos afectadas si solo se busca predicci√≥n (no interpretaci√≥n)
- **Inferencia**: Muy afectada (intervalos de confianza, pruebas de hip√≥tesis)
- **Toma de decisiones**: Riesgo de conclusiones incorrectas sobre qu√© variables importan

---

## üìà Mejores Pr√°cticas

### Para Mejorar el Modelo:

1. **Divisi√≥n Train/Test**: Usar 70-30 o 80-20 para validaci√≥n
2. **Validaci√≥n Cruzada**: k-fold CV para estimar rendimiento real
3. **Regularizaci√≥n**: Ridge o Lasso para prevenir sobreajuste
4. **Ingenier√≠a de Caracter√≠sticas**: Crear interacciones o t√©rminos polinomiales
5. **An√°lisis de Outliers**: Detectar y tratar valores at√≠picos influyentes

### Para Comunicar Resultados:

1. **Usar gr√°ficos claros**: Los visuales facilitan la comprensi√≥n
2. **Contextualizar m√©tricas**: RMSE de $500 puede ser mucho o poco seg√∫n el CLV promedio
3. **Reportar incertidumbre**: Siempre incluir intervalos de confianza
4. **Validar en nuevos datos**: La prueba real es el rendimiento out-of-sample

---

## üÜò Soluci√≥n de Problemas

### Error: "ModuleNotFoundError"
```bash
pip install --upgrade [nombre_del_m√≥dulo]
```

### Error: "ValueError: shapes not aligned"
- Verificar que todas las variables est√©n completas (sin NaN)
- Usar `df.dropna()` si es necesario

### Gr√°ficos no se muestran
```python
%matplotlib inline  # En Jupyter
plt.show()          # En scripts Python
```

---

## üìö Recursos Adicionales

- [Documentaci√≥n Statsmodels](https://www.statsmodels.org/)
- [Scikit-learn User Guide](https://scikit-learn.org/stable/user_guide.html)
- [Curso de Regresi√≥n Lineal - Coursera](https://www.coursera.org/)
- [Introduction to Statistical Learning](https://www.statlearning.com/) - Libro gratuito

---

## üìù Notas Finales

Este proyecto es un **ejercicio educativo** con datos sint√©ticos. En un proyecto real:

- Usa datos hist√≥ricos reales de clientes
- Valida el modelo en datos futuros (out-of-time validation)
- Considera factores externos (estacionalidad, econom√≠a, competencia)
- Actualiza el modelo peri√≥dicamente
- Incorpora feedback del negocio sobre la utilidad de las predicciones

## Test final educativo
![quiz](modeloRegresionLineal.png)